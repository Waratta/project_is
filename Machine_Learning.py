import streamlit as st
import pandas as pd

st.title("Machine Learning")

st.text("‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö California Housing Prices | ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏±‡∏ê‡πÅ‡∏Ñ‡∏•‡∏¥‡∏ü‡∏≠‡πÄ‡∏ô‡∏µ‡∏¢")
st.markdown("download ‡∏°‡∏≤‡∏à‡∏≤‡∏Å https://www.kaggle.com/datasets/camnugent/california-housing-prices")

st.write("## üìå‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ feature ‡∏Ç‡∏≠‡∏á Dataset")
df = pd.DataFrame(
    {
        "‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå": ["longitude", "latitude"
                ,"housing_median_age","total_rooms","total_bedrooms","population",
                "households","median_income","median_house_value","ocean_proximity"],

        "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢": ["‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏≠‡∏≤‡∏®‡∏±‡∏¢", "‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏≠‡∏≤‡∏®‡∏±‡∏¢"
                ,"‡∏≠‡∏≤‡∏¢‡∏∏‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ô‡∏±‡πâ‡∏ô(‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏µ)","‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πâ‡∏ô"
                ,"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πâ‡∏ô","‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πâ‡∏ô",
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πâ‡∏ô","‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏£‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡∏≠‡∏ô(‡∏ß‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏™‡∏´‡∏£‡∏±‡∏ê)"
                ,"‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πâ‡∏ô","‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏´‡∏≤‡∏™‡∏°‡∏∏‡∏ó‡∏£"]
    }
)
st.data_editor(
    df,
    column_config={
        "‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå":"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå",
        "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢": st.column_config.TextColumn(
            "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢",
            default="st.",
            max_chars=50,
            validate=r"^st\.[a-z_]+$",
        )
    },
    hide_index=True,
)

st.write("## üìå‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
st.markdown("1. Pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏°‡∏±‡∏ò‡∏¢‡∏ê‡∏≤‡∏ô(median) ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‡πÄ‡πÄ‡∏•‡∏∞‡πÉ‡∏ä‡πâ StandardScaler() ‡∏ó‡∏≥ Feature Scaling")

code = '''# Pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
num_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])'''
st.code(code, language="python")

st.markdown("2. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å ocean_proximity ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (Categorical) ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ One-Hot Encoding")

code = '''# Pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
cat_pipeline = Pipeline([
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])'''
st.code(code, language="python")

st.markdown("3. ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á Pipeline ‡πÉ‡∏ä‡πâ ColumnTransformer() ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á Numerical Pipeline ‡πÅ‡∏•‡∏∞ Categorical Pipeline")

code = '''# ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å Pipeline
preprocessor = ColumnTransformer([
    ("num", num_pipeline, num_features),
    ("cat", cat_pipeline, cat_features)
])'''
st.code(code, language="python")


st.write("## üìå‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á Linear Regression")
st.markdown("&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‡πÄ‡∏õ‡πá‡∏ô Machine Learning ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Supervised Learning ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏≤‡∏° "
"‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏≤‡∏°")
st.markdown("‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Linear Regression ‡∏Ñ‡∏∑‡∏≠ : y = mx + c")

col1, col2 = st.columns(2)

with col1:
    st.markdown("- x ‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πâ‡∏ô(Input) ")
    st.markdown("- y ‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏≤‡∏°(Output) ")

with col2:
    st.markdown("- m ‡∏Ñ‡∏∑‡∏≠ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ô ")
    st.markdown("- c ‡∏Ñ‡∏∑‡∏≠ ‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î‡πÅ‡∏Å‡∏ô y ")

st.write("## üìå‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á Random Forest Regressor")
st.markdown("&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Random Forest = ‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏≤‡∏¢ Decision Tree ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ dataset ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô"
"‡∏ó‡∏≥ prediction ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Tree ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏ß‡∏°‡∏ú‡∏•‡πÇ‡∏î‡∏¢:\n"
"- Classification ‚Üí ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ vote ‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î\n "
"- Regression ‚Üí ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ mean ‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n"
"\n‡πÅ‡∏ï‡πà‡∏•‡∏∞ Decision Tree ‡πÄ‡∏õ‡πá‡∏ô weak learner ‚Üí ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏î‡πâ model ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô")

st.write("## üìå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•")
st.markdown("1. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train & Test")

code = '''from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)'''
st.code(code, language="python")

st.markdown("2. ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏™‡∏£‡πâ‡∏≤‡∏á Dictionary ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear Regression ‡πÅ‡∏•‡∏∞ Random Forest")
code = '''# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest Regressor": RandomForestRegressor(n_estimators=100, random_state=42)
}'''
st.code(code, language="python")

st.markdown("‚úÖ ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\n"
            "1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline (preprocessor + regressor)\n"
            "2. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ .fit()\n"
            "3. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢ .predict()\n"
            "4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Absolute Error (MAE)\n"
            "5. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Root Mean Squared Error (RMSE)")

code = '''results = []
feature_importance = {}

for model_name, model in models.items():
    pipeline = Pipeline([("preprocessor", preprocessor), ("regressor", model)])
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    results.append({"Model": model_name, "MAE": mae, "RMSE": rmse})
    
    if hasattr(model, 'feature_importances_'):
        feature_importance[model_name] = model.feature_importances_
'''
st.code(code, language="python")

st.markdown("3. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô Streamlit ‡πÅ‡∏™‡∏î‡∏á ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (MAE & RMSE) ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö DataFrame ‡πÉ‡∏ä‡πâ Seaborn Bar Chart ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•")
code = '''# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô Streamlit
results_df = pd.DataFrame(results)
st.write("## ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
st.dataframe(results_df)

# ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö MAE ‡πÅ‡∏•‡∏∞ RMSE
fig, ax = plt.subplots(1, 2, figsize=(12, 5))

# ‡∏Å‡∏£‡∏≤‡∏ü MAE
sns.barplot(x="Model", y="MAE", data=results_df, ax=ax[0], palette="Blues_r")
ax[0].set_title("Mean Absolute Error (MAE)")
ax[0].set_ylabel("MAE")
ax[0].set_xlabel("Model")

# ‡∏Å‡∏£‡∏≤‡∏ü RMSE
sns.barplot(x="Model", y="RMSE", data=results_df, ax=ax[1], palette="Reds_r")
ax[1].set_title("Root Mean Squared Error (RMSE)")
ax[1].set_ylabel("RMSE")
ax[1].set_xlabel("Model")

st.pyplot(fig)
'''
st.code(code, language="python")