import streamlit as st
import pandas as pd

st.title("Neural Network")

st.text("‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö mnist | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠")
st.markdown("download ‡∏°‡∏≤‡∏à‡∏≤‡∏Å https://www.kaggle.com/datasets/oddrationale/mnist-in-csv")

st.write("## üìå‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ feature ‡∏Ç‡∏≠‡∏á Dataset")

df =pd.DataFrame( {
    '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•': ['Label', '1x1 ‡∏ñ‡∏∂‡∏á 28x28'],
    '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î': [
        '‡∏Ñ‡πà‡∏≤‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ (0-9)',
        '‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡∏ô‡∏≤‡∏î 28x28 (‡∏Ñ‡πà‡∏≤ 0-255)'
    ]
}
)
st.data_editor(
    df,
    column_config={
        "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•":"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
        "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": st.column_config.TextColumn(
            "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢",
            default="st.",
            max_chars=50,
            validate=r"^st\.[a-z_]+$",
        )
    },
    hide_index=True,
)

st.write("## üìå‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
st.markdown("1.‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô csv ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ç‡∏ô‡∏≤‡∏î 28x28 ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏• ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á (csv) ‡πÇ‡∏î‡∏¢‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏°‡∏µ :\n "
"\n- ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå label ‚Üí ‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á (0-9)\n"
"\n- 784 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (pixel1 ‡∏ñ‡∏∂‡∏á pixel784) ‚Üí ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡∏≠‡∏á‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà 0-255\n")


st.markdown("2.‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏ä‡πâ pandas ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏≠‡∏¥‡∏™‡∏£‡∏∞ (X) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (y)")

code = '''# Load dataset
file_path = "mnist_test.csv"
df = pd.read_csv(file_path)

# Split features and labels
y = df["label"].values
X = df.drop("label", axis=1).values / 255.0  # Normalize pixel values'''
st.code(code, language="python")

st.markdown("3. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preprocessing)  ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ Normalization\n "
"\n- ‡∏Ñ‡πà‡∏≤ Pixel ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏°‡∏µ‡∏ä‡πà‡∏ß‡∏á 0-255\n"
"\n- ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-1 ‡πÇ‡∏î‡∏¢‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 255 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏•‡∏î Overfitting")

code = '''X = X / 255.0'''
st.code(code, language="python")

st.write("## üìå‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á Multilayer Perceptron (MLP)")
st.markdown("&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Neural Network ‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô Layer ‡πÇ‡∏î‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡πÑ‡∏´‡∏•‡πÉ‡∏ô‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (Feedforward)\n"
"\nMulti-Layer Perceptron (MLP) ‚Üí ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÇ‡∏´‡∏ô‡∏î‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (Fully-Connected)")

st.markdown("- Input Layer ‚Üí ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ (Feature)")
st.markdown("- Hidden Layer ‚Üí ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á ‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞ Neuron ‡πÑ‡∏î‡πâ)  ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Deep Learning")
st.markdown("- Output Layer ‚Üí ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏≠‡∏Å‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå")

st.write("## üìå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•")
st.markdown("1. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Architecture) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô create_model() ‡πÉ‡∏ä‡πâ TensorFlow/Keras ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÑ‡∏ß‡πâ")

code = '''# Define model
def create_model():
    model = keras.Sequential([
        layers.Input(shape=(784,)),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model'''
st.code(code, language="python")

st.markdown("2. ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÉ‡∏ä‡πâ model.summary() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞ Layer ‡∏ï‡πà‡∏≤‡∏á‡πÜ")

code = '''# Function to convert model summary to string
def get_model_summary(model):
    string_io = io.StringIO()
    model.summary(print_fn=lambda x: string_io.write(x + "\n"))
    summary_string = string_io.getvalue()
    string_io.close()
    return summary_string

# Display model summary
st.subheader("Model Summary")
summary_string = get_model_summary(model)

st.code(summary_string, language="text")
'''
st.code(code, language="python")

st.markdown("3. ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Training)\n "
"\n- ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'Train Model' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å\n "
"\n- ‡πÉ‡∏ä‡πâ model.fit() ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• 5 ‡∏£‡∏≠‡∏ö (epochs = 5)\n "
"\n- ‡πÉ‡∏ä‡πâ batch_size = 32 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡πà‡∏≤‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏∏‡∏Å ‡πÜ 32 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á \n"
"\n- ‡πÉ‡∏ä‡πâ validation_split = 0.1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")

code = '''if st.button("Train Model"):
    with st.spinner("Training in progress..."):
        history = model.fit(X, y, epochs=5, batch_size=32, validation_split=0.1, verbose=0)
    st.success("Training complete!")'''
st.code(code, language="python")

st.markdown("4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n "
"\n- history.history['accuracy'] ‚Üí ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î Train\n "
"\n- history.history['val_accuracy'] ‚Üí ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î Validation")

code = '''# Display results
    st.write("Final Training Accuracy:", history.history['accuracy'][-1])
    st.write("Final Validation Accuracy:", history.history['val_accuracy'][-1])'''
st.code(code, language="python")

st.markdown("5.‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å (Training Visualization) ‡πÉ‡∏ä‡πâ Matplotlib ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü:\n"
"\n- Accuracy (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•)\n"
"\n- Loss (‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)")

code = '''# Plot training history
    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    
    ax[0].plot(history.history['accuracy'], label='Training Accuracy')
    ax[0].plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax[0].set_title("Model Accuracy")
    ax[0].set_xlabel("Epoch")
    ax[0].set_ylabel("Accuracy")
    ax[0].legend()
    
    ax[1].plot(history.history['loss'], label='Training Loss')
    ax[1].plot(history.history['val_loss'], label='Validation Loss')
    ax[1].set_title("Model Loss")
    ax[1].set_xlabel("Epoch")
    ax[1].set_ylabel("Loss")
    ax[1].legend()
    
    st.pyplot(fig)'''
st.code(code, language="python")

st.markdown("<p style='text-align: right;'>‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å chatGPT</p>",
            unsafe_allow_html=True)

